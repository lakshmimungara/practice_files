Day-50 session-50(26/10/2024)
-------------------------------
k8 resources 
1.namespace
2.pod 
	resources
	env
	label
	annotations
3.configmap
4.secret
5.services
	cluster IP 
	nodePort 
	LoadBalancer
LoadBalancer > nodePort > cluster IP 

what are the uses of service?
1. pod to pod communication using DNS and load Balancer purpose. Expose your pod using services to access from internet 

Everything is in a yaml file syntax 
------------------------------------
kind: 
apiVersion: 
metadata: 
	name: 
	labels:
spec: 

Now in today's class
----------------------
sets:
-----
1. ReplicaSet 
2. DeploymentSet 
3. SaemonSet 
4. StatefulSet 

ReplicaSet:
-----------
-> It makes sure your desired number of pods running all the time 
-> A ReplicaSet's purpose is to maintain a stable set of replica Pods running at any given time 
-> Usually, you define a Deployment and let that Deployment manage ReplicaSets automatically 
-> we don't have an option to choose or select the pod 
-> ReplicaSet needs 3 pods
 
How it will select the pods? 
A) Through selectors 

In kubernetes, one resources is attached to another resources is only possible through labels 


15-replicaset.yaml 


apiVersion: apps/v1 
kind: ReplicaSet
metadata: 
	name: nginx 
	labels:  # these are replicaset labels 
	   app: nginx 
	   tier: frontend 
spec: 
	# modify replicas according to your case 
	replicas: 3 
	selector: 
	  # these are used to select the pd to create replicas
	  matchLabels:
		tier: frontend
		app: nginx		
	# this is pod definition 
	template: 
	  metadata:
		# these labels belongs to pod 
	    labels: 
		  tier: frontend
		  app: nginx
	  spec: 
	    containers: 
		- name: nginx 
		  image: nginx 

		  
kubectl apply -f 15-replicaset.yaml 
kubectl get pods (three pods running)
kubectl get replicasets
kubectl delete pod <pod-name>
kubectl get pods

apiVersion: apps/v1 
kind: ReplicaSet
metadata: 
	name: nginx 
	labels:  # these are replicaset labels 
	   app: nginx 
	   tier: frontend 
spec: 
	# modify replicas according to your case 
	replicas: 3 
	selector: 
	  # these are used to select the pd to create replicas
	  matchLabels:
		tier: frontend
		app: nginx		
	# this is pod definition 
	template: 
	  metadata:
		# these labels belongs to pod 
	    labels: 
		  tier: frontend
		  app: nginx
	  spec: 
	    containers: 
		- name: nginx 
		  image: nginx 
---
apiVersion: v1 
kind: Service 
metadata:
	name: nginx 
spec: 
	selector: 
		tier: frontend
		app: nginx	 
	ports: 
	- name: nginx-svc-port
	  protocol: TCP 
	  port: 80 # service port 
	  targetPort: 80 # container port
	  

kubectl apply -f 15-replicaset.yaml 
kubectl describe service nginx (we will get three ip addresses -> it load balances the three ip addresses)

apiVersion: apps/v1 
kind: ReplicaSet
metadata: 
	name: nginx 
	labels:  # these are replicaset labels 
	   app: nginx 
	   tier: frontend 
spec: 
	# modify replicas according to your case 
	replicas: 3 
	selector: 
	  # these are used to select the pd to create replicas
	  matchLabels:
		tier: frontend
		app: nginx		
	# this is pod definition 
	template: 
	  metadata:
		# these labels belongs to pod 
	    labels: 
		  tier: frontend
		  app: nginx
	  spec: 
	    containers: 
		- name: nginx 
		  image: nginx:stable-perl 
---
apiVersion: v1 
kind: Service 
metadata:
	name: nginx 
spec: 
	selector: 
		tier: frontend
		app: nginx	 
	ports: 
	- name: nginx-svc-port
	  protocol: TCP 
	  port: 80 # service port 
	  targetPort: 80 # container port


kubectl apply -f 15-replicaset.yaml
kubectl get pods (pods not get updated)

-> replicaset cannot update the image version. It's only responsibilities is to main desired no.of  replicas

kubectl apply -f 02-pod.yaml 
kubectl get pods (nginx get created)

apiVersion: v1
kind: Pod
metadata:
  name: nginx
spec:
  containers:
  # docker run -d --name nginx nginx
  - name: nginx
    image: nginx:stable-perl
	
kubectl apply -f 02-pod.yaml
kubectl get pods (nginx get restarted, previous version got deleted and running with the new version) -> This is called deployment 

So, we have a solution called deployment

deployment:
------------
-> This deployment can handle the changes 

first delete the replicaset
---------------------------
kubectl delete -f 15-replicaset.yaml 

Disadvantage of replicaset:
---------------------------
-> It will not update the pods if there is any version changes are there 


 
16-deployment.yaml 

apiVersion: apps/v1 
kind: Deployment
metadata: 
	name: nginx 
	labels:  # these are replicaset labels 
	   app: nginx 
	   tier: frontend 
spec: 
	# modify replicas according to your case 
	replicas: 3 
	selector: 
	  # these are used to select the pd to create replicas
	  matchLabels:
		tier: frontend
		app: nginx		
	# this is pod definition 
	template: 
	  metadata:
		# these labels belongs to pod 
	    labels: 
		  tier: frontend
		  app: nginx
	  spec: 
	    containers: 
		- name: nginx 
		  image: nginx:stable-perl 
---
apiVersion: v1 
kind: Service 
metadata:
	name: nginx 
spec: 
	selector: 
		tier: frontend
		app: nginx	 
	ports: 
	- name: nginx-svc-port
	  protocol: TCP 
	  port: 80 # service port 
	  targetPort: 80 # container port
	  
kubectl apply -f 16-deployment.yaml 
kubectl get pods 
kubectl get deployment
kubectl get replicaset

-> deployment will create replicaset. So replicaset is subset/part of deployment


what if we updated the image? 

apiVersion: apps/v1 
kind: Deployment
metadata: 
	name: nginx 
	labels:  # these are replicaset labels 
	   app: nginx 
	   tier: frontend 
spec: 
	# modify replicas according to your case 
	replicas: 3 
	selector: 
	  # these are used to select the pd to create replicas
	  matchLabels:
		tier: frontend
		app: nginx		
	# this is pod definition 
	template: 
	  metadata:
		# these labels belongs to pod 
	    labels: 
		  tier: frontend
		  app: nginx
	  spec: 
	    containers: 
		- name: nginx 
		  image: nginx
---
apiVersion: v1 
kind: Service 
metadata:
	name: nginx 
spec: 
	selector: 
		tier: frontend
		app: nginx	 
	ports: 
	- name: nginx-svc-port
	  protocol: TCP 
	  port: 80 # service port 
	  targetPort: 80 # container port
	  
	  
kubectl apply -f 16-deployment.yaml 
kubectl get pods 
kubectl get replicaset (internally it updates the image)

Change the replicas to 30

apiVersion: apps/v1 
kind: Deployment
metadata: 
	name: nginx 
	labels:  # these are replicaset labels 
	   app: nginx 
	   tier: frontend 
spec: 
	# modify replicas according to your case 
	replicas: 30 
	selector: 
	  # these are used to select the pd to create replicas
	  matchLabels:
		tier: frontend
		app: nginx		
	# this is pod definition 
	template: 
	  metadata:
		# these labels belongs to pod 
	    labels: 
		  tier: frontend
		  app: nginx
	  spec: 
	    containers: 
		- name: nginx 
		  image: nginx
---
apiVersion: v1 
kind: Service 
metadata:
	name: nginx 
spec: 
	selector: 
		tier: frontend
		app: nginx	 
	ports: 
	- name: nginx-svc-port
	  protocol: TCP 
	  port: 80 # service port 
	  targetPort: 80 # container port
	  
kubectl apply -f 16-deployment.yaml 
kubectl get pods 
watch kubectl get pods (it updates for every two seconds and shows the result)

-> Updating the image with the new version 

apiVersion: apps/v1 
kind: Deployment
metadata: 
	name: nginx 
	labels:  # these are replicaset labels 
	   app: nginx 
	   tier: frontend 
spec: 
	# modify replicas according to your case 
	replicas: 30 
	selector: 
	  # these are used to select the pd to create replicas
	  matchLabels:
		tier: frontend
		app: nginx		
	# this is pod definition 
	template: 
	  metadata:
		# these labels belongs to pod 
	    labels: 
		  tier: frontend
		  app: nginx
	  spec: 
	    containers: 
		- name: nginx 
		  image: nginx:stable-perl
---
apiVersion: v1 
kind: Service 
metadata:
	name: nginx 
spec: 
	selector: 
		tier: frontend
		app: nginx	 
	ports: 
	- name: nginx-svc-port
	  protocol: TCP 
	  port: 80 # service port 
	  targetPort: 80 # container port

kubectl apply -f 16-deployment.yaml 
kubectl get pods (it creates new one and deletes the old one)

Important for interviewss:
================================
-> deployment is used to create a replicaset. when you update the image deployment make sure there is n down time it will create a new replicaset and it will creates the new pod and delete the old pod 

-> pod is a subset of replicaset and replicaset is a subset of deployment

-> we have container in pod, pod manages the replicaset and replicaset manages the deployment


Now expense project 
-------------------

create a new repo -> expense-k8 
git clone <https url>
first we will create a namespace 

namespace.yaml 

apiVersion: v1
kind: Namespace
metadata:
  name: expense
  labels:
    project: expense
    environment: dev
	
kubectl apply -f namespace.yaml 
kubectl get deployment
kubectl delete deployment nginx 
kubectl get pods 


mysql
-----
mainfest.yaml 

-> no one creates the pod directly in a project. becoz it is difficult to manage the pods individually. so, the better option is always a deployment 

apiVersion: apps/v1
kind: Deployment
metadata:
  name: mysql
  namespace: expense
  labels:
    app: mysql
	tier: db 
	project: expense
spec:
  replicas: 1
  selector:
    matchLabels:
      app: mysql
	  tier: db 
	  project: expense
  template:
    metadata:
      labels:
        app: mysql
	    tier: db 
	    project: expense
    spec:
      containers:
      - name: mysql
        image: mahalakshmi2997/mysql:v1
        

kubectl apply -f manifest.yaml 
kubectl get pods -n expense (-n indicates namespace)
kubectl exec -it <pod-name> -n expense -- bash 
mysql -u root -pExpenseApp@1 
show databases;
use transacations; 
show tables;


apiVersion: apps/v1
kind: Deployment
metadata:
  name: mysql
  namespace: expense
  labels:
    app: mysql
	tier: db 
	project: expense
spec:
  replicas: 1
  selector:
    matchLabels:
      app: mysql
	  tier: db 
	  project: expense
  template:
    metadata:
      labels:
        app: mysql
	    tier: db 
	    project: expense
    spec:
      containers:
      - name: mysql
        image: mahalakshmi2997/mysql:v1
		
---
apiVersion: v1 
kind: Service 
metadata:
	name: mysql 
	namespace: expense 
spec: 
	selector: 
	  app: mysql
	  tier: db 
	  project: expense	 
	ports: 
	- name: mysql-port
	  protocol: TCP 
	  port: 3306 # service port 
	  targetPort: 3306 # container port
	  
kubectl apply -f manifest.yaml 
kubectl get svc -n expense (svc is a shortcut for service)


backend:
----------
manifest.yaml 

apiVersion: v1 
kind: ConfigMap 
metadata: 
	name: backend 
	namespace: expense
data: 
	DB_HOST: mysql
---
apiVersion: apps/v1
kind: Deployment
metadata:
  name: backend 
  namespace: expense
  labels:
    app: backend
	tier: api 
	project: expense
spec:
  replicas: 2
  selector:
    matchLabels:
      app: backend
	  tier: api 
	  project: expense
  template:
    metadata:
      labels:
        app: backend
		tier: api
	    project: expense
    spec:
      containers:
      - name: backend
        image: mahalakshmi2997/backend:v1
		envFrom:
		- configMapRef:
			name: backend
		
---
apiVersion: v1 
kind: Service 
metadata:
	name: backend
	namespace: expense 
spec: 
	selector: 
	  app: backend
	  tier: api
	  project: expense	 
	ports: 
	- name: backend-port
	  protocol: TCP 
	  port: 8080 # service port 
	  targetPort: 8080 # container port
	  
kubectl apply -f manifest.yaml 
kubectl get pods -n expense
kubectl logs <pod-name> -n expense

sudo git clone https://github.com/ahmetb/kubectx /opt/kubectx
sudo ln -s /opt/kubectx/kubectx  /usr/local/bin/kubectx
sudo ln -s /opt/kubectx/kubecns  /usr/local/bin/kubecns
kubecns expense 
kubectl get pods 
kubectl exec -it <pod-name> -- sh (we use sh for minimal images)
telnet mysql 3306 

In expense-docker-1 folder
------------------------------
debug:
------
create one Dockerfile 

FROM almalinux:9 
RUN dnf install telnet -y 
CMD ["sleep", "20000"]

-> first you have install docker in the server 
-> follow the steps 
-> docker build -t mahalakshmi2997/debug:v1 . 
-> docker login -u mahalakshmi2997
-> docker push mahalakshmi2997/debug:v1 


debug:
------
manifest.yaml 


apiVersion: v1
kind: Pod
metadata:
  name: debug 
  namespace: expense 
spec:
  containers:
  # docker run -d --name nginx nginx
  - name: debug
    image: mahalakshmi2997/debug:v1 
	
kubectl apply -f manifest.yaml
kubectl get pods 
kubectl exec -it debug -- bash 
telnet mysql 3306 
telnet backend 8080 
curl http://backend:8080/health 


frontend:
---------
manifest.yaml 

apiVersion: apps/v1
kind: Deployment
metadata:
  name: frontend
  namespace: expense
  labels:
    app: frontend
    tier: web
    project: expense
spec:
  replicas: 2
  selector:
    matchLabels:
      app: frontend
      tier: web
      project: expense
  template:
    metadata:
      labels:
        app: frontend
        tier: web
        project: expense
    spec:
      containers:
      - name: frontend
        image: mahalakshmi2997/frontend:v1
---
kind: Service
apiVersion: v1
metadata:
  name: frontend
  namespace: expense
spec:
  type: LoadBalancer
  selector:
    app: frontend
    tier: web
    project: expense
  ports:
  - name: frontend-port
    protocol: TCP
    port: 80 # service port
    targetPort: 80 # container port
	
kubectl apply -f manifest.yaml 
kubectl get svc  (which shows the port number: 32070)

In loadbalancer -> allow the traffic in security groups -> eks-cluster-sg-expense

route53 -> alias to application and classic loadbalancer 
select the option which shows 
access the application in chrome 
